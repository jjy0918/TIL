# 3. 카프카 기본 개념 설명

## 3.1 카프카 브로커, 클러스터, 주키퍼

- 카프카 브로커: 클라이언트와 데이터를 주고 받기 위해 사용하는 주체.
- 하나의 서버에는 하나의 카프카 브로커 프로세스가 실행된다.
- 안전한 데이터 처리를 위해 하나의 클러스터 서버안에 3대의 브로커를 묶어서 관리한다.
- 브로커 = 1대의 서버.
- 브로커 안에 토픽들의 파티션이 들어 있다.

### 데이터 저장, 전송

- 프로듀서로부터 데이터를 전달 받으면, 카프카 브로커는 해당 토픽의 파티션에 데이터를 저장한다.
- 데이터는 파일 시스템으로 저장된다.
- 메모리나 데이터베이스에 저장하지 않기 때문에 캐시 메모리를 구현할 필요가 없다.
- 캐시를 사용하는 것이 속도가 더 빠르고, 디스크 I/O는 더 느리다.
- 카프카는 페이지 캐시(Page Cache)를 이용하여 디스크 I/O 성능을 향상시켰다.
  - 페이지 캐시란 한 번 디스크에서 읽은 데이터를 메모리에 올려 놓아 사용하는 것이다.
  - 해당 데이터는 메모리에 올려져 있기 때문에 디스크 I/O는 중복되서 발생하기 않아 효율적이다.
- 페이지 캐시를 이용하기 때문에 별도의 캐시를 구현하지 않아도 되고, GC도 적게 일어나서 성능 향상이 가능해졌다.


#### 카프카 속도 향상 전략

- 카프카의 일원화된 데이터(바이너리 데이터)
  - 카프카의 데이터(메시지) 들은 모두 바이너리 형식으로 구성되어 있다.
  - 일반적으로 데이터 전송은 4단계로 구성된다.
    1. OS는 디스크에서 커널 공간의 페이지 캐시로 데이터를 읽습니다.
    2. 응용 프로그램은 커널 공간에서 사용자 공간 버퍼로 데이터를 읽습니다.
    3. 응용 프로그램은 데이터를 다시 커널 공간에 소켓 버퍼에 씁니다.
    4. OS는 소켓 버퍼에서 네트워크를 통해 전송되는 NIC 버퍼로 데이터를 복사합니다.
  - 카프카는 4단계 중 2번째 단계를 생략할 수 있다.
  - 데이터 형식이 같기 때문에 커널 페이지 캐시 -> 소켓 버퍼로 바로 데이터를 전송할 수 있다.
> https://www.freecodecamp.org/news/what-makes-apache-kafka-so-fast-a8d4f94ab145/


#### 카프카 캐시 전략

- 카프카는 페이지 캐시를 사용한다.
- 캐시에는 여러 전략이 존재한다.(LRU, LFU 등)
- 카프카에서는 캐시 전략을 LRU로 사용한다.
- ` Records are evicted using a simple LRU scheme after the cache size is reached. `
> https://kafka.apache.org/28/documentation/streams/developer-guide/memory-mgmt.html


### 데이터 복제, 싱크

- 카프카는 복제를 통해 장애 복구 시스템을 지원한다.
- 복제는 파티션 단위로 이루어진다.
- 토픽을 생성할 때 파티션의 복제 개수도 설정하는데, 따로 설정하지 않으면 브로커 개수 만큼 생성이 된다.
- 복제된 파티션은 `리더(leader)`와 `팔로워(follower)`로 구성된다.
  - 리더는 프로듀서, 컨슈머와 직접 통신한다.
  - 팔로워는 복제 데이터를 가지고 있는다.
- 팔로워 파티션들은 리더 파티션의 오프셋을 확인하여 차이가 날 경우 리더로부터 데이터를 가져와 저장한다.
- 복제는 모든 팔로워 파티션에서 일어나기 때문에 복제 개수 만큼 저장 용령이 늘어난다.
- 리더 파티션에 장애가 발생할 경우, 팔로워 파티션 중 하나는 리더가 된다.
- 일반적으로 안정성보다는 속도가 중시되면 복제 개수를 1 또는 2로 설정하고 안정성이 중시된다면 3 이상으로 설정한다.

### 컨트롤러(controller)

- 다수의 브로커 중 하나가 컨트롤러 역할을 한다.
- 컨트롤러는 다른 브로커들의 상태를 체크하고 장애가 발생할 경우 리더 파티션을 재분배하는 역할을 한다.
- 컨트롤러 브로커에 장애가 발생하면, 다른 브로커가 컨트롤러 역할을 한다.

### 데이터 삭제

- 카프카는 컨슈머가 데이터를 가져가도 토픽의 데이터는 삭제되지 않는다.
- 컨슈머나 프로듀서는 데이터 `삭제` 요청을 할 수 없다.
- 데이터 `삭제`는 오직 `브로커`만 가능하다.
- 데이터 삭제는 `로그 세그먼트(파일 단위)`로 이루어진다.
  - 즉, 특정 데이터만 삭제하는 것은 불가능하다.
- 세그먼트 파일은 `log.retention.bytes` 또는 `log.retention.ms` 옵션에 따라 삭제된다.
- `log.retention.check.interval.ms`를 기준으로 세그먼트 파일을 체크한다.

### 컨슈머 오프셋 저장

- 컨슈머 그룹이 특정 파티션으로부터 데이터를 가져가면 오프셋을 `_consumer_offsets` 토픽에 저장한다.

### 코디네이터(coordinator)

- 다수의 브로커 중 한 대는 코디네이터의 역할을 한다.
- 코디네이터는 컨슈머 그룹 상태를 체크하여 파티션과 컨슈머 매칭을 분배한다.
- 파티션을 컨슈머로 재할당하는 과정을 `리밸런스`라고 부르다.

### 주키퍼

- 주키퍼는 카프카의 메타데이터 관리를 하는데 사용된다.
- 카프카 클러스터로 묶인 브로커들은 동일한 경로의 주키퍼 경로로 선언해야 같은 카프카 브로커 묶음이 된다.

## 3.2 토픽과 파티션

- `토픽`은 데이터를 구분하기 위해 사용하는 단위이다.
- 카프카는 데이터를 가져가도 삭제가 되는 것이 아니기 때문에 컨슈머 그룹마다 데이터를 전략에 따라 다르게 가져가서 사용할 수 있다.

### 의미 있는 토픽 이름 작명 방법

- 토픽은 의미 있는 이름으로 사용해야 한다.
- 영어 대소문자와 마침표, 언더바, 하이픈을 넣을 수 있지만, `휴먼 에러`를 방지하기 위해 `카멜 케이스`보다는 `케밥 케이스`, `스네이크 케이스`를 사용하는 것이 좋다.
- ex) <환경>.<팀-명>.<애플리케이션-명>.<메시지-타입>
- prd.marketing-team.sms-platform.json
- 카프카는 토픽 이름 변경을 지원하지 않기 때문에 이름을 변경하기 위해서는 삭제 후 다시 생성해야 한다.

## 3.3 레코드

- 레코드는 `타임스탬프`, `메시지 키`, `오프셋`, `헤더`로 구성되어 있다.
- 프로듀서가 레코드를 브로커로 전송하면, 오프셋과 타임스탬프가 지정되어 저장된다.
- 브로커에 적재된 레코드는 수정할 수 없고, 로그 리텐션 기간 또는 용량에 따라서만 삭제된다.

### 타임스탬프
- 타임스탬프는 레코드가 생성된 시점의 유닉스 타임이 설정된다.
- 프로듀서가 임의의 타임스탬프 값을 설정하 수 있다.
- 토픽 설정에 따라 적재된 시간으로 설정될 수 있다.

### 메시지 키

- 메시지 키는 메시지 값을 순서대로 처리하거나 메시지 값의 종류를 나타내기 위해 사용된다.
- 메시지 키 값의 해시값을 이용하여 파티션을 지정한다.
- 어느 파티션에 지정될 지는 알 수 없고, 같은 파티션이라는 것만 알 수 있다.
- 메시지 키를 지정하지 않으면 null로 설정되고, 프로듀서 기본 설정 파티셔너에 따라 파티션에 분배된다.

### 메시지 값

- 메시지 값에는 실질적으로 처리할 데이터가 들어 있다.
- 메시지 키, 값은 직렬화되어 전송되기 때문에 직렬화, 역직렬화 시 반드시 동일한 형태로 처리해야 한다.

### 오프셋

- 오프셋은 직접 지정할 수 없다.
- 브로커에 저장될 때 이전에 전송된 레코드 오프셋+1 값을 저장한다.
- 오프셋은 컨슈머가 데이터를 가져갈 때 사용된다.

## 3.4 카프카 클라이언트

### 3.4.1 프로듀서 API

- 프로듀서는 파티셔너를 가지고 있다.
- 파티셔너가 키 값을 바탕으로 파티션을 결정한다.
- KafkaProducer는 전송하는 역할을 한다.
- ProducerRecord는 키, 값을 가진 레코드이다.

#### 프로듀서 중요 개념

- 프로듀서는 카프카 브로커로 데이터를 전송할 때 내부적으로 `파티셔너`, `배치 생성` 단계를 거친다.
- `ProducerRecord` 인스턴스를 생성하여 토픽과 메시지 등을 설정할 수 있다.
- `KafkaProducer` 인스턴스의 `send` 메소드를 호출하면, 파티셔너에서 어느 토픽의 어느 파티션으로 전송될 지 정해진다.
  - `kafkaProducer.send(producerRecodr);`
  - `KafkaProducer` 인스턴스 생성 시 파티셔너 설정을 하지 않으면 기본 파티셔너가 설정된다.
- 레코드들은 데이터 전송 전 어큐뮬레이터(accumulator)에 데이터를 버퍼로 쌓아 놓고  발송한다.
- 버퍼로 쌓인 데이터는 배치로 묶어서 전송하기 때문에 처리량 향상시키는데 큰 도움이 된다.
- 기본 파티셔너로 `UniformStickyPartitioner`와 `RoundRobinPartitioner`가 있다.
  - 메시지 키가 없을 때 파티션에 최대한 동일하게 분배하는 로직이 들어 있다.
  - `UniformStickyPartitioner`는 `RoundRobinPartitioner`을 개선한 것이다.
  - `RoundRobinPartitioner` 는 데이터가 들어오면, 바로 순회하며 데이터를 전송한다.
  - `UniformStickyPartitioner`는 어큐뮬레이터에 데이터를 쌓은 후 데이터를 전송한다.(데이터가 쌓이거나 시간이 지나면 새로운 파티션을 찾음)
- `Partitioner` 인터페이스를 구현하여 사용자 정의 파티셔너를 만들 수 있다.
- 또한, 데이터 전송 시 압축 기능을 제공한다.
  - 압축 옵션으로는 gzip, nappy, lz4, zstd를 지원한다.
  - 데이터를 압축하여 네트워크 처리량을 향상시킬 수 있지만, CPU와 메모리 사용량은 늘어난다.


#### 프로듀서 주요 옵션

- 필수 옵션
  - bootstrap.server: 카프카 클러스터에 속한 브로커의 호스트 이름:포트를 1개 이상 작성한다.(2개 이상 적어 하나가 접속에 문제가 있어도 접속이 가능하도록 설정)
  - key.serializer: 레코드의 메시지 키를 직렬화하는 클래스.
  - value.serializer: 레코드의 메시지 값을 직렬화하는 클래스.

- 선택 옵션
  - acks: 프로듀서가 브로커에 데이터를 정상적으로 저장되었는지 확인하는데 사용.
    - 0: 전송한 즉시 데이터 저장 여부와 상관 없이 성공으로 판단.
    - 1(default): 리더 파티션에 저장되면 성공으로 판단.
    - -1(all): 토픽의 min.insync.replicas 개수에 해당하는 리더 파티션과 팔로워 파티션에 데이터가 저정되면 성공으로 판단.
  - buffer.memory: 브로커로 전송할 데이터를 배치에 모으기 위해 설정할 버퍼 메모리량. 기본값은 32MB이다.
  - retries: 브로커로부터 에러 메시지를 받으면 재전송 시도 횟수. 기본값은 2147483647이다.
  - batch.size: 배치로 전송할 레코드 최대 용량. 기본값은 16384
  - linger.ms: 배치를 전송하기 전까지 기다리는 최소 시간. 기본값은 0
  - patitioner.class: 레코드를 파티션에 전송할 때 적용하는 파티셔너 클래스. 기본값은 DefaultPartitioner
  - enable.idempotence: 멱등성 프로듀서 설정 여부. 기본값은 false
  - transcational.id: 트랜잭션 단위로 묶을지 설정. 기본값은 null
