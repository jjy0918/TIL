# 3.4 카프카 클라이언트

## 3.4.1 프로듀서 API

- 프로듀서는 파티셔너를 가지고 있다.
- 파티셔너가 키 값을 바탕으로 파티션을 결정한다.
- KafkaProducer는 전송하는 역할을 한다.
- ProducerRecord는 키, 값을 가진 레코드이다.

### 프로듀서 중요 개념

- 프로듀서는 카프카 브로커로 데이터를 전송할 때 내부적으로 `파티셔너`, `배치 생성` 단계를 거친다.
- `ProducerRecord` 인스턴스를 생성하여 토픽과 메시지 등을 설정할 수 있다.
- `KafkaProducer` 인스턴스의 `send` 메소드를 호출하면, 파티셔너에서 어느 토픽의 어느 파티션으로 전송될 지 정해진다.
  - `kafkaProducer.send(producerRecodr);`
  - `KafkaProducer` 인스턴스 생성 시 파티셔너 설정을 하지 않으면 기본 파티셔너가 설정된다.
- 레코드들은 데이터 전송 전 어큐뮬레이터(accumulator)에 데이터를 버퍼로 쌓아 놓고 발송한다.
- 버퍼로 쌓인 데이터는 배치로 묶어서 전송하기 때문에 처리량 향상시키는데 큰 도움이 된다.
- 기본 파티셔너로 `UniformStickyPartitioner`와 `RoundRobinPartitioner`가 있다.
  - 메시지 키가 없을 때 파티션에 최대한 동일하게 분배하는 로직이 들어 있다.
  - `UniformStickyPartitioner`는 `RoundRobinPartitioner`을 개선한 것이다.
  - `RoundRobinPartitioner` 는 데이터가 들어오면, 바로 순회하며 데이터를 전송한다.
  - `UniformStickyPartitioner`는 어큐뮬레이터에 데이터를 쌓은 후 데이터를 전송한다.(데이터가 쌓이거나 시간이 지나면 새로운 파티션을 찾음)
- `Partitioner` 인터페이스를 구현하여 사용자 정의 파티셔너를 만들 수 있다.
- 또한, 데이터 전송 시 압축 기능을 제공한다.
  - 압축 옵션으로는 gzip, nappy, lz4, zstd를 지원한다.
  - 데이터를 압축하여 네트워크 처리량을 향상시킬 수 있지만, CPU와 메모리 사용량은 늘어난다.

### 프로듀서 주요 옵션

- 필수 옵션

  - bootstrap.server: 카프카 클러스터에 속한 브로커의 호스트 이름:포트를 1개 이상 작성한다.(2개 이상 적어 하나가 접속에 문제가 있어도 접속이 가능하도록 설정)
  - key.serializer: 레코드의 메시지 키를 직렬화하는 클래스.
  - value.serializer: 레코드의 메시지 값을 직렬화하는 클래스.

- 선택 옵션
  - acks: 프로듀서가 브로커에 데이터를 정상적으로 저장되었는지 확인하는데 사용.
    - 0: 전송한 즉시 데이터 저장 여부와 상관 없이 성공으로 판단.
    - 1(default): 리더 파티션에 저장되면 성공으로 판단.
    - -1(all): 토픽의 min.insync.replicas 개수에 해당하는 리더 파티션과 팔로워 파티션에 데이터가 저정되면 성공으로 판단.
  - buffer.memory: 브로커로 전송할 데이터를 배치에 모으기 위해 설정할 버퍼 메모리량. 기본값은 32MB이다.
  - retries: 브로커로부터 에러 메시지를 받으면 재전송 시도 횟수. 기본값은 2147483647이다.
  - batch.size: 배치로 전송할 레코드 최대 용량. 기본값은 16384
  - linger.ms: 배치를 전송하기 전까지 기다리는 최소 시간. 기본값은 0
  - patitioner.class: 레코드를 파티션에 전송할 때 적용하는 파티셔너 클래스. 기본값은 DefaultPartitioner
  - enable.idempotence: 멱등성 프로듀서 설정 여부. 기본값은 false
  - transcational.id: 트랜잭션 단위로 묶을지 설정. 기본값은 null

## 3.4.2 컨슈머 API

- 프로듀서가 데이터를 브로커에 적재하면, 컨슈머는 적재된 데이터를 가져와 사용한다.

### 카프카 컨슈머 프로젝트 생성

```kotlin

class SimpleConsumer {
    companion object {
        private val logger = LoggerFactory.getLogger(SimpleConsumer.javaClass)
        private val TOPIC_NAME = "test"
        private val BOOTSTRAP_SERVERS = "my-kafka:9092"
        private val GROUP_ID = "test-group"
    }

    fun startConsumer() {
        val config = Properties()
        config[ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG] = BOOTSTRAP_SERVERS
        config[ConsumerConfig.GROUP_ID_CONFIG] = GROUP_ID
        config[ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG] = StringDeserializer::class.java.name
        config[ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG] = StringDeserializer::class.java.name

        val consumer = KafkaConsumer<String, String>(config)
        consumer.subscribe(listOf(TOPIC_NAME))

        while (true) {
            val record = consumer.poll(Duration.ofSeconds(1))

            record.forEach{
                logger.info(it)
            }
        }

    }
}

```

### 컨슈머 주요 개념

- 컨슈머 운영 방법은 2가지가 있다.
  1. 1개 이상의 컨슈머로 이루어진 컨슈머 그룹을 운영하는 방법.
  2. 토픽의 특정 파티션만 구독하는 방법.

### 컨슈머 그룹

- 컨슈머 그륩으로 운영하면, 컨슈머를 각 컨슈머 그룹으로부터 격리된 환경에서 안전하게 운영할 수 있도록 도와준다.
- 컨슈머 그룹으로 묶인 컨슈머들은 1개 이상 파티션들에 할당되어 데이터를 가져갈 수 있다.
  - 1개 파티션은 최대 1개의 컨슈머에 할당 가능하다.
  - 1개의 컨슈머는 여러 개의 파티션에 할당될 수 있다.
  - 파티션과 컨슈머는 다대일 관계이다.
  - 즉, `컨슈머 그룹의 컨슈머 개수는 토픽의 파티션 개수보다 같거나 작아야 한다.`
  - 컨슈머 개수가 더 많을 경우, 스레드만 차지하고 실질적 데이터를 처리하지 못하는 컨슈머가 유휴 상태로 남게 된다.
- 컨슈머 그룹은 다른 컨슈머 그룹과 격리되는 특징을 가진다.
  - 컨슈머 그룹끼리 같은 프로듀서가 보낸 데이터를 서로가 영향을 받지 않고 처리할 수 있다.
  - 컨슈머 그룹으로 분리하여 데이터 적재, 처리 등을 안전하게 운영할 수 있다.
- 컨슈머 그룹에 장애가 발생하여 특정 컨슈머에 문제가 생기면 발생하지 않은 컨슈머로 소유권을 넘기는 리밸런싱을 진행한다.
  - 리벨런싱은 그룹 조정자(group coordination)으로 설정된 브로커가 진행한다.
  - 리벨런싱이 진행되는 동안 데이터를 읽을 수 없기 때문에 주의가 필요하다.
- 컨슈머는 커밋을 통해 브로커로부터 데이터를 얼마나 가져갔는지 판단한다.
  - 브로커 내부에 컨슈 토픽에는 컨슈머 그룹이 데이터를 얼마나 가져갔는지 저장되어 있다.
  - 데이터 중복을 방지하기 위해서 오프셋 커밋이 정상적인지 검증해야 한다.
- 오프셋 커밋은 기본값이 일정 간격마다 수행하도록 되어 있지만, 자동 커밋을 안하도록 설정이 가능하다.
  - 비명시 오프셋 커밋은 리벨런싱할 때 데이터 중복이나 유실 가능성이 있기 때문에 주의가 필요하다.
- 컨슈머 내부적으로 poll을 통해 데이터를 가져오는데, 실제로는 poll을 실행했을 때 데이터를 가져오는 것이 아니다.
  - 내부에 Fetcher 인스턴스는 poll 호출 전 레코드들을 미리 큐로 가져오고, 사용자가 poll 호출 시 큐에서 레코드를 가져온다.

### 컨슈머 주요 옵션

- 필수 옵션
  - bootstrap.servers: 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커 이름:포트. 2개 이상 입력하여 이슈 방지 가능.
  - key.desirealizer: 레코드의 메시지 키를 역직렬화하는 클래스 지정.
  - value.desirealizer: 레코드의 메시지 값을 역직렬화 하는 클래스 지정.
- 선택 옵션
  - group.id: 컨슈머 그룹 아이디 지정. subscribe() 메서드로 토픽을 구독할 때 사용한다.(기본 값은 null이다.)
  - audo.offset.reset: 파티션을 읽을 때 저장된 컨슈머 오프셋이 없는 경우 어떻게 읽을지 선택하는 옵션
    - `이미 컨슈머 오프셋이 있다면 무시된다.`
    - latest: 가장 높은(최근) 오프셋부터 읽는다. 기본값이다.
    - earlist: 가장 늦은(가장 오래 전) 오프셋부터 읽는다.
    - none: 커밋한 기록을 찾아 읽는다. 커밋 기록이 없다면 오류를 반환한다.
  - enable.auto.commit: 자동 커밋, 수동 커밋 여부 설정. 기본값은 true이다.
  - auto.commit.interval.ms: 자동 커밋 시 커밋 오프셋 간격. 기본 값은 5000(5초)이다.
  - max.poll.records: poll 메서드를 통해 반환되는 레코드 개수. 기본 값은 500이다.
  - session.timeout.ms: 컨슈머가 브로커와 연결이 끊기는 최대 시간.
    - 이 시간 안에 heartbeat를 전송하지 않으면 리밸런싱 시작한다.
    - 보통, heartbeat 시간 간격의 3배로 설정한다.
    - 기본 값은 10000(10초)이다.
  - heartbeat.interval.ms: heartbeat를 전송하는 시간 간격. 기본 값은 3000(3초)이다.
  - max.poll.interval.ms: poll 메서드를 호출하는 간격의 최대 시간.
    - 데이터 처리하는 시간이 너무 많이 걸리면 리벨런싱 진행.
    - 기본 값은 300000(5분)이다.
  - isolation.level: 트랜잭션 프로듀서가 레코드를 트랜잭션 단위로 보낼 때 사용한다.
    - read_committed: 커밋 완료된 레코드만 읽는다.
    - read_uncommitted: 커밋 여부와 관계 없이 파티션에 있는 모든 레코드를 읽는다.
    - 기본 값은 read_uncoommitted이다.

### 동기 오프셋, 비동기 오프셋

- 카프카에서 commitSync() 메서드 호출 시 오프셋 커밋을 명시적으로 수행한다.
  - commitSync는 poll 메서드로 받은 가장 마지막 레코드의 오프셋을 기준으로 커밋한다.
  - 데이터 처리가 끝난 후 commitSync()를 실행해야 한다.
  - commitSync 실행 후 브로커로부터 오프셋 커밋이 완료되기 까지 기다린다.
  - 개별 레코드 단위로 오프셋을 커밋하고 싶다면 commitSync 메소드에 Map<TopicPartition, OffsetAndMetaData> 인스턴스를 파라미터로 넣으면 된다.
- 카프카에서 commitAsync() 메서드 호출 시 비동기로 오프셋 커밋을 실행한다.
  - 기본적으로 commitSync 처럼 poll 메서드로 받은 가장 마지막 레코드 오프셋을 기준으로 커밋한다.
  - callBack 함수를 통해 커밋 응답을 받아 처리할 수 있다.
- 레코드 단위로 오프셋을 사용할 때에는 현재 처리하는 오프셋에 1을 더한 값을 커밋해야 한다.
  - 컨슈머는 poll을 수행할 때 마지막으로 커밋한 오프셋부터 리턴한다.

### 리벨런스 리스너

- 카프카의 ConsumerRebalanceListener 인터페이스를 통해 리벨런싱 실행 전, 후 행위를 구현할 수 있다.
- onPartitionAssigned 메서드를 통해 리벨런싱 후 실행할 행위를 구현한다.
- onPartitionRevoked 메서드를 통해 리벌렌싱 시작 전 행위를 구현한다.

### 파티션 할당 컨슈머

- subscribe외에도 assign 메서드를 이용하여 명시적으로 컨슈머를 할당할 수 있다.
- subscribe와 달리 직접 컨슈머가 특정 토픽, 특정 파티션을 할당하기 때문에 리벨런싱 과정이 없다.

## 3.4.3 어드민 API

- KafkaAdminClient를 이용하여 다양한 어드민 기능을 사용할 수 있다.
- describeCluster(DescribeClusterOptions options): 브로커의 정보 조회
- listTopics(ListTopicOptions options): 토픽 리스트 조회
- listConsumerGroups(ListConsumerGroupOptions options): 컨슈머 그룹 조회
- createTopics(Collection<NewTopic> newTopics, CreateTopicOptions options): 신규 토픽 생성
- createPatitions(Map<String, NewPartitions> newPartitions, CreatePartitionsOptions options): 파티션 개수 변경
- createAcls(Collection<AclBinding> acls, CreateAclsOptions options): 접근 제어 규칙 생성
